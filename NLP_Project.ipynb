{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Movie Review - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Python file we will proceed with building the classification model using SkLearn\n",
    "* Naive Bayes using Multinomial and Bernoulli \n",
    "* Support Vector Machine (SVM)\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as p\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Read and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the training data\n",
    "\n",
    "# the data set includes four columns: PhraseId, SentenceId, Phrase, Sentiment\n",
    "# the Phrase column includes the review text\n",
    "# the Sentiment column includes the score:-\n",
    "# \"0\" for very negative\n",
    "# \"1\" for negative\n",
    "# \"2\" for neutral\n",
    "# \"3\" for positive\n",
    "# \"4\" for very positive\n",
    "\n",
    "train=p.read_csv(\"./train.tsv\", delimiter='\\t')\n",
    "test =p.read_csv(\"./test.tsv\", delimiter='\\t') \n",
    "y=train['Sentiment'].values\n",
    "X=train['Phrase'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      "PhraseId      156060 non-null int64\n",
      "SentenceId    156060 non-null int64\n",
      "Phrase        156060 non-null object\n",
      "Sentiment     156060 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGDCAYAAAAmkGrdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de7hddX3v+/dHAoooBSRyMEHRGi/Irgg5EEUrBQsBL9A+8Ii9EN20UQ92V7e9oHYXRTlbu1utWC+bXVJAq4hWj9GNxWwuXgEJiCBGJCKSCIVIAqIoGvieP8Zv4XQx18p1ZmWN9X49z3zmGL/xG7/xHXOuZH3WuMyZqkKSJKlPHjHVBUiSJG1tBhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxpG0jyoST/barr2BhJzknyjjb9giQ3bsWxP59kUZt+ZZKvbMWx/zDJF7bWeJuw3UOT3JTkJ0mO29bbH6jjodd2Kk2nn3X1W/wcHM1USZ4P/B3wLOABYAXw+qq6agvHfSXwJ1X1/C0ucgsleSvw1Kr6o01Y5xxgdVX9zYi380o283VKsi/wfWDHqlq/qetvTUkuBpZW1Xunsg5Jv27WVBcgTYUkuwKfA14LXADsBLwAuH8q6+qrJKH7g+rBqa5lBJ4E3DDVRWwtSWZNdWiUtgZPUWmmehpAVX2sqh6oqp9V1Req6rqxDkn+c5IVSdYluSjJkwaWVZLXtFMT65K8P51nAh8CnttOWdzd+g+e9jksyeokf5XkziS3JzkuyTFJvptkbZI3D2zrEUlOTfK9JHcluSDJHm3Zvq2WRUluTfKjJG9pyxYCbwZe3mr55rAXIslzklyT5N4kHwceNbDssCSrB+b/OskPW98bkxwx0XaSXJbkjCRfBe4DntLa/uTXN5/3JbknyXeSHDGw4JYkLxqYf2uSj7TZL7Xnu9s2nzv+lFeS5yW5qo19VZLnDSy7LMnbk3y17csXkuw57PVp/f80ycr23ixN8oTW/j3gKcBnWx2PHLLuLUn+Msl1SX6a5Owke7VTSvcm+T9Jdh/o/7IkNyS5u9X5zNZ+apJPjhv7vUnOHNinPxlYNuHP77gxxn6GTk5yK3BJa1+Q5Gutjm8mOay1n5hk+bgx3pBkaZt+6Ge9zb8kybVtnK8l+a3W/qoknx3otzLJBQPzq5IckM570v1buae9jvtP9F5JD6kqHz5m3APYFbgLOBc4Gth93PLjgJXAM+mOdP4N8LWB5UV3BGg34InAGmBhW/ZK4CvjxjsHeEebPgxYD/wtsCPwp239jwKPpTtl9nPgKa3/64ErgLnAI4H/CXysLdu31fK/gJ2BZ9MdhXpmW/5W4COTvA47AT8A3tBqOR745bhaV7fppwOrgCcMbPs3J9oOcBlwa9ufWW38y+hOS429TusHtv1y4B5gj7b8FuBFA+M9tI2B/Z41sPyh1x3YA1gH/HHb9iva/OMGavseXdDduc2/c4LX6HDgR8CB7fV/H/ClgeW/VueQ9W9p799ewBzgTuAa4DltvEuA01rfpwE/BX63vSZ/RfdzuBPdkaL7gF1b3x2A24EFA/s09tpO+vM7rr6x1/I8YJf2esyh+/dxDN0fwr/b5mcDjwbuBeYNjHEVcOKQn/UD2/4e0upd1F6PR9IFw7vb+HvT/Rz+sK33lPZ+PQI4Cria7t9a2j7tPdX/h/jY/h8ewdGMVFU/Bp7Pr8LBmvaX+V6ty6uB/15VK6o7XP//AgeM+yv4nVV1d1XdClwKHLAJJfwSOKOqfgmcD+wJvLeq7q2qG+hOefzWQC1vqarVVXU/3S/645MMnmJ+W3VHob4JfJMu6GyMBXS/SP+xqn5ZVZ+k+2U1zAN0v5j2S7JjVd1SVd/bwPjnVNUNVbW+7et4dw5s++PAjcCLN7L2ybwYuKmqPty2/THgO8BLB/r8S1V9t6p+RneacqL37w+BJVV1TXv930R3hG7fTajnfVV1R1X9EPgycGVVfaON92m6sANdyPvfVbWsvV5/Txc4nldVP6ALRmMXMh8O3FdVVwzZ3sb8/I731qr6aXs9/gi4sKourKoHq2oZsBw4pqruAz5DFxpJMg94BrB0yJh/CvzPqrqyuiOl59IF8AVVdTNdUDoAeCFwEfDDJM9o81+u7pTmL+mC/zPoTnOuqKrbJ9kPCfAUlWaw9h/lK6tqLrA/8ATgH9viJwHvbYfV7wbW0v31OGdgiP8YmL4PeMwmbP6uqnqgTf+sPd8xsPxnA+M9Cfj0QC0r6MLGXgP9N7eWJ9D91Tx4t8EPhnWsqpV0R5PeCtyZ5PyxUzWTWLWB5cO2vaExN8YTePh+/IDNe/9+bayq+gnd0Yw5E/QfZvx7O9F7PX5bD9K9hmPb+igtWAB/0OaH2Zif3/EG36snASeMrd/GeD7dkZZhdfx/LfgMq+ON48bZh1+9x1+kO0r42236Mrpw88I2T1VdAvwT8H7gjiRnpbuGTpqUAUcCquo7dIfWx87trwJeXVW7DTx2rqqvbcxwW7m8VcDR42p5VDsasKW13A7MSZKBtidOOFjVR6u76+lJbex3bWA7G9r+sG3f1qZ/Snc6ZMz/tQnj3tZqHPREYGNes0nHSrIL8LjNHGtTtxW6QDC2rU8AhyWZC/weEweczfn5HXxNVwEfHrf+LlX1zrb8C8CeSQ6gCzqT1XHGuHEe3Y6owa8Czgva9BcZF3AAqurMqjqI7nTn04C/nGQ/JMCAoxkqyTOSvLH9oiDJPnT/UY8d7v8Q8KYkz2rLfyPJCRs5/B3A3CQ7baVyPwScMXZ6IcnsJMduQi37Jpno3/rldNfB/Jcks5L8PnDwsI5Jnp7k8HYh7c/pjjyMHYXa0HYm8vi27R3b6/tM4MK27FrgxLZsPt31QWPWAA/SXasxzIXA05L8QduvlwP70V03tak+CryqXfD6SLrTPVdW1S2bMdaGXAC8ON3F2zsCb6Q7pfM1gKpaQ3eU41+A71fVignG2ZKfX4CPAC9NclSSHZI8Kt0F53NbHeuBTwL/g+56p2UTjPO/gNckOaRdLLxLkhcneWxb/kXgd4Cdq2o13em7hXQB8hut9v+7rb8jXej9Ob/6uZMmZMDRTHUv3YWPVyb5KV2w+RbdLxSq6tN0RyfOT/LjtuzojRz7ErpraP4jyY+2Qq3vpbu+4QtJ7m21HrKR636iPd+V5JrxC6vqF8Dv012gu47uGpBPTTDWI4F30l1w+x904WTsbq9JtzOJK4F5bcwzgOOr6q627L8Bv9nqehsDRwna6ZAzgK+2Ux8Lxu3XXcBL6N7Pu+gu1n1JVW3y+1FVF7da/o3uiNdvAidu6jgbua0b6a5/eR/da/JS4KXtfRrzUeBFTHzUZEt/fqmqVcCxdO/vGrojMX/Jr//OGKvjEzXBbeVVtZzuOpx/onsfV9L9rI0t/y7wE7pgM3Zt3M3AVwdO4e5KF5TW0Z2+u4vu2iRpUn7QnyRJ6h2P4EiSpN4x4EiSpN4x4EiSpN4x4EiSpN4x4EiSpN6Zcd8mvueee9a+++471WVIkqSt4Oqrr/5RVc0e3z7jAs6+++7L8uXLN9xRkiRt95IM/XoZT1FJkqTeMeBIkqTeMeBIkqTeMeBIkqTeMeBIkqTeMeBIkqTeMeBIkqTeMeBIkqTeGWnASfKGJDck+VaSjyV5VJInJ7kyyU1JPp5kp9b3kW1+ZVu+78A4b2rtNyY5aqB9YWtbmeTUUe6LJEmaPkYWcJLMAf4LML+q9gd2AE4E3gW8p6rmAeuAk9sqJwPrquqpwHtaP5Ls19Z7FrAQ+ECSHZLsALwfOBrYD3hF6ytJkma4UZ+imgXsnGQW8GjgduBw4JNt+bnAcW362DZPW35EkrT286vq/qr6PrASOLg9VlbVzVX1C+D81leSJM1wIws4VfVD4O+BW+mCzT3A1cDdVbW+dVsNzGnTc4BVbd31rf/jBtvHrTNRuyRJmuFGeYpqd7ojKk8GngDsQnc6abwaW2WCZZvaPqyWxUmWJ1m+Zs2aDZUuSZKmuVF+m/iLgO9X1RqAJJ8CngfslmRWO0ozF7it9V8N7AOsbqe0fgNYO9A+ZnCdidp/TVWdBZwFMH/+/KEhSNLGO/R9h051CdPeV//sq1NdgtRro7wG51ZgQZJHt2tpjgC+DVwKHN/6LAI+06aXtnna8kuqqlr7ie0uqycD84CvA1cB89pdWTvRXYi8dIT7I0mSpomRHcGpqiuTfBK4BlgPfIPuKMr/Bs5P8o7WdnZb5Wzgw0lW0h25ObGNc0OSC+jC0XrglKp6ACDJ64CL6O7QWlJVN4xqfyRJ0vQxylNUVNVpwGnjmm+muwNqfN+fAydMMM4ZwBlD2i8ELtzySiVJUp/4ScaSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3DDiSJKl3RhZwkjw9ybUDjx8neX2SPZIsS3JTe9699U+SM5OsTHJdkgMHxlrU+t+UZNFA+0FJrm/rnJkko9ofSZI0fYws4FTVjVV1QFUdABwE3Ad8GjgVuLiq5gEXt3mAo4F57bEY+CBAkj2A04BDgIOB08ZCUeuzeGC9haPaH0mSNH1sq1NURwDfq6ofAMcC57b2c4Hj2vSxwHnVuQLYLcnewFHAsqpaW1XrgGXAwrZs16q6vKoKOG9gLEmSNINtq4BzIvCxNr1XVd0O0J4f39rnAKsG1lnd2iZrXz2kXZIkzXAjDzhJdgJeBnxiQ12HtNVmtA+rYXGS5UmWr1mzZgNlSJKk6W5bHME5Grimqu5o83e000u05ztb+2pgn4H15gK3baB97pD2h6mqs6pqflXNnz179hbujiRJ2t5ti4DzCn51egpgKTB2J9Qi4DMD7Se1u6kWAPe0U1gXAUcm2b1dXHwkcFFbdm+SBe3uqZMGxpIkSTPYrFEOnuTRwO8Crx5ofidwQZKTgVuBE1r7hcAxwEq6O65eBVBVa5O8Hbiq9Tu9qta26dcC5wA7A59vD0mSNMONNOBU1X3A48a13UV3V9X4vgWcMsE4S4AlQ9qXA/tvlWIlSVJv+EnGkiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpdww4kiSpd0YacJLsluSTSb6TZEWS5ybZI8myJDe1591b3yQ5M8nKJNclOXBgnEWt/01JFg20H5Tk+rbOmUkyyv2RJEnTw6iP4LwX+PeqegbwbGAFcCpwcVXNAy5u8wBHA/PaYzHwQYAkewCnAYcABwOnjYWi1mfxwHoLR7w/kiRpGhhZwEmyK/DbwNkAVfWLqrobOBY4t3U7FziuTR8LnFedK4DdkuwNHAUsq6q1VbUOWAYsbMt2rarLq6qA8wbGkiRJM9goj+A8BVgD/EuSbyT55yS7AHtV1e0A7fnxrf8cYNXA+qtb22Ttq4e0S5KkGW6UAWcWcCDwwap6DvBTfnU6aphh18/UZrQ/fOBkcZLlSZavWbNm8qolSdK0N8qAsxpYXVVXtvlP0gWeO9rpJdrznQP99xlYfy5w2wba5w5pf5iqOquq5lfV/NmzZ2/RTkmSpO3fyAJOVf0HsCrJ01vTEcC3gaXA2J1Qi4DPtOmlwEntbqoFwD3tFNZFwJFJdm8XFx8JXNSW3ZtkQbt76qSBsSRJ0gw2a8Tj/xnwr0l2Am4GXkUXqi5IcjJwK3BC63shcAywEriv9aWq1iZ5O3BV63d6Va1t068FzgF2Bj7fHpIkaYYbacCpqmuB+UMWHTGkbwGnTDDOEmDJkPblwP5bWKYkSeoZP8lYkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1jgFHkiT1zkgDTpJbklyf5Noky1vbHkmWJbmpPe/e2pPkzCQrk1yX5MCBcRa1/jclWTTQflAbf2VbN6PcH0mSND1siyM4v1NVB1TV/DZ/KnBxVc0DLm7zAEcD89pjMfBB6AIRcBpwCHAwcNpYKGp9Fg+st3D0uyNJkrZ3U3GK6ljg3DZ9LnDcQPt51bkC2C3J3sBRwLKqWltV64BlwMK2bNequryqCjhvYCxJkjSDjTrgFPCFJFcnWdza9qqq2wHa8+Nb+xxg1cC6q1vbZO2rh7RLkqQZbtaIxz+0qm5L8nhgWZLvTNJ32PUztRntDx+4C1eLAZ74xCdOXrEkSZr2RnoEp6pua893Ap+mu4bmjnZ6ifZ8Z+u+GthnYPW5wG0baJ87pH1YHWdV1fyqmj979uwt3S1JkrSdG1nASbJLkseOTQNHAt8ClgJjd0ItAj7TppcCJ7W7qRYA97RTWBcBRybZvV1cfCRwUVt2b5IF7e6pkwbGkiRJM9goT1HtBXy63bk9C/hoVf17kquAC5KcDNwKnND6XwgcA6wE7gNeBVBVa5O8Hbiq9Tu9qta26dcC5wA7A59vD0mSNMONLOBU1c3As4e03wUcMaS9gFMmGGsJsGRI+3Jg/y0uVpIk9YqfZCxJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknpn1kQLkqwDatgioKpqj5FVJUmStAUmDDjAntusCkmSpK1owoBTVQ8MzifZA3jUQNNtoypKkiRpS2zwGpwkL07yXWA1cGV7vmTUhUmSJG2ujbnI+AzgUODGqtoHOAq4bJRFSZIkbYmNCTjrq2oN8IgkqaplwIEjrkuSJGmzTXaR8Zh7kuwCfAU4L8mdwIOjLUuSJGnzbcwRnOOAnwOvpzs19UPgJSOsSZIkaYtsTMB5U1U9UFW/rKqzq+rdwH8ddWGSJEmba2MCzsIhbS/e2oVIkiRtLZN9kvGrgdcAT0tyzcCixwLLR12YJEnS5prsIuMLgIuB/w6cOtB+b1XdOdKqJEmStsBkn2S8DlgHnJBkf+D5bdGXAQOOJEnabm3MJxmfQnc054ntcUGS/2djN5BkhyTfSPK5Nv/kJFcmuSnJx5Ps1Nof2eZXtuX7DozxptZ+Y5KjBtoXtraVSU4dv21JkjQzbcxFxq8GDq6qN1fVm4FD6K7N2Vh/DqwYmH8X8J6qmkd3hOjk1n4ysK6qngq8p/UjyX7AicCz6C54/kALTTsA7weOBvYDXtH6SpKkGW5jAk6AXw7M/7K1bXjFZC7dHVf/3OYDHA58snU5l+5zdgCObfO05Ue0/scC51fV/VX1fWAlcHB7rKyqm6vqF8D5ra8kSZrhJruLalZVrQc+DFyR5N/aot/jV0FkQ/4R+Cu6O68AHgfc3caF7os757TpOcAqgKpan+Se1n8OcMXAmIPrrBrXfshG1iVJknpssiM4Xweoqr8DFgP3AT8DXlNVf7+hgZO8BLizqq4ebB7StTawbFPbh9WyOMnyJMvXrFkzSdWSJKkPJrtN/KEAUVVXAVdt4tiHAi9LcgzwKGBXuiM6uw0cHZoL3Nb6rwb2AVYnmQX8BrB2oH3M4DoTtf+aqjoLOAtg/vz5Q0OQJEnqj8kCzuwkE34lQ/vKhglV1ZuANwEkOQz4i6r6wySfAI6nu2ZmEfCZtsrSNn95W35JVVWSpcBHk7wbeAIwj+7oUoB5SZ5M9/1YJwJ/MPnuSpKkmWCygLMD8Bg28oLiTfDXwPlJ3gF8Azi7tZ8NfDjJSrojNycCVNUNSS4Avg2sB06pqgcAkrwOuKjVuqSqbtjKtUqSpGlosoBze1WdvjU2UlWX0X0TOVV1M90dUOP7/Bw4YYL1zwDOGNJ+IXDh1qhRkiT1x2QXGW/tIzeSJEnbxGQB54htVoUkSdJWNGHAqaq127IQSZKkrWVjPslYkiRpWjHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3jHgSJKk3pk11QVIkrbcF3/7hVNdwrT2wi99capL0FbmERxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7Iws4SR6V5OtJvpnkhiRva+1PTnJlkpuSfDzJTq39kW1+ZVu+78BYb2rtNyY5aqB9YWtbmeTUUe2LJEmaXkZ5BOd+4PCqejZwALAwyQLgXcB7qmoesA44ufU/GVhXVU8F3tP6kWQ/4ETgWcBC4ANJdkiyA/B+4GhgP+AVra8kSZrhRhZwqvOTNrtjexRwOPDJ1n4ucFybPrbN05YfkSSt/fyqur+qvg+sBA5uj5VVdXNV/QI4v/WVJEkz3EivwWlHWq4F7gSWAd8D7q6q9a3LamBOm54DrAJoy+8BHjfYPm6didolSdIMN9KAU1UPVNUBwFy6Iy7PHNatPWeCZZva/jBJFidZnmT5mjVrNly4JEma1rbJXVRVdTdwGbAA2C3J2Jd8zgVua9OrgX0A2vLfANYOto9bZ6L2Yds/q6rmV9X82bNnb41dkiRJ27FR3kU1O8lubXpn4EXACuBS4PjWbRHwmTa9tM3Tll9SVdXaT2x3WT0ZmAd8HbgKmNfuytqJ7kLkpaPaH0mSNH3M2nCXzbY3cG672+kRwAVV9bkk3wbOT/IO4BvA2a3/2cCHk6ykO3JzIkBV3ZDkAuDbwHrglKp6ACDJ64CLgB2AJVV1wwj3R5IkTRMjCzhVdR3wnCHtN9NdjzO+/efACROMdQZwxpD2C4ELt7hYSZLUK36SsSRJ6h0DjiRJ6h0DjiRJ6h0DjiRJ6h0DjiRJ6p1R3iYubTW3nv6fprqEae2Jf3v9VJcgSduUR3AkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvGHAkSVLvjCzgJNknyaVJViS5Icmft/Y9kixLclN73r21J8mZSVYmuS7JgQNjLWr9b0qyaKD9oCTXt3XOTJJR7Y8kSZo+RnkEZz3wxqp6JrAAOCXJfsCpwMVVNQ+4uM0DHA3Ma4/FwAehC0TAacAhwMHAaWOhqPVZPLDewhHujyRJmiZGFnCq6vaquqZN3wusAOYAxwLntm7nAse16WOB86pzBbBbkr2Bo4BlVbW2qtYBy4CFbdmuVXV5VRVw3sBYkiRpBtsm1+Ak2Rd4DnAlsFdV3Q5dCAIe37rNAVYNrLa6tU3WvnpIuyRJmuFGHnCSPAb4N+D1VfXjyboOaavNaB9Ww+Iky5MsX7NmzYZKliRJ09xIA06SHenCzb9W1ada8x3t9BLt+c7WvhrYZ2D1ucBtG2ifO6T9YarqrKqaX1XzZ8+evWU7JUmStnujvIsqwNnAiqp698CipcDYnVCLgM8MtJ/U7qZaANzTTmFdBByZZPd2cfGRwEVt2b1JFrRtnTQwliRJmsFmjXDsQ4E/Bq5Pcm1rezPwTuCCJCcDtwIntGUXAscAK4H7gFcBVNXaJG8Hrmr9Tq+qtW36tcA5wM7A59tDkiTNcCMLOFX1FYZfJwNwxJD+BZwywVhLgCVD2pcD+29BmZIkqYf8JGNJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7BhxJktQ7Iws4SZYkuTPJtwba9kiyLMlN7Xn31p4kZyZZmeS6JAcOrLOo9b8pyaKB9oOSXN/WOTNJRrUvkiRpehnlEZxzgIXj2k4FLq6qecDFbR7gaGBeeywGPghdIAJOAw4BDgZOGwtFrc/igfXGb0uSJM1QIws4VfUlYO245mOBc9v0ucBxA+3nVecKYLckewNHAcuqam1VrQOWAQvbsl2r6vKqKuC8gbEkSdIMt62vwdmrqm4HaM+Pb+1zgFUD/Va3tsnaVw9plyRJ2m4uMh52/UxtRvvwwZPFSZYnWb5mzZrNLFGSJE0X2zrg3NFOL9Ge72ztq4F9BvrNBW7bQPvcIe1DVdVZVTW/qubPnj17i3dCkiRt37Z1wFkKjN0JtQj4zED7Se1uqgXAPe0U1kXAkUl2bxcXHwlc1Jbdm2RBu3vqpIGxJEnSDDdrVAMn+RhwGLBnktV0d0O9E7ggycnArcAJrfuFwDHASuA+4FUAVbU2yduBq1q/06tq7MLl19LdqbUz8Pn2kCRpyv3TGz871SVMe6/7h5du0fojCzhV9YoJFh0xpG8Bp0wwzhJgyZD25cD+W1KjJEnqp+3lImNJkqStxoAjSZJ6x4AjSZJ6x4AjSZJ6x4AjSZJ6x5/hOUgAAAc7SURBVIAjSZJ6Z2S3iU93B/3leVNdwrR29f84aapLkCTNYB7BkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvWPAkSRJvTPtA06ShUluTLIyyalTXY8kSZp60zrgJNkBeD9wNLAf8Iok+01tVZIkaapN64ADHAysrKqbq+oXwPnAsVNckyRJmmLTPeDMAVYNzK9ubZIkaQZLVU11DZstyQnAUVX1J23+j4GDq+rPxvVbDCxus08HbtymhY7GnsCPproIPcT3Y/vje7J98f3Y/vTlPXlSVc0e3zhrKirZilYD+wzMzwVuG9+pqs4CztpWRW0LSZZX1fyprkMd34/tj+/J9sX3Y/vT9/dkup+iugqYl+TJSXYCTgSWTnFNkiRpik3rIzhVtT7J64CLgB2AJVV1wxSXJUmSpti0DjgAVXUhcOFU1zEFenXKrQd8P7Y/vifbF9+P7U+v35NpfZGxJEnSMNP9GhxJkqSHMeBMM341xfYlyZIkdyb51lTXIkiyT5JLk6xIckOSP5/qmma6JI9K8vUk32zvydumuiZ13wSQ5BtJPjfVtYyKAWca8asptkvnAAunugg9ZD3wxqp6JrAAOMV/I1PufuDwqno2cACwMMmCKa5J8OfAiqkuYpQMONOLX02xnamqLwFrp7oOdarq9qq6pk3fS/cfuJ9uPoWq85M2u2N7ePHnFEoyF3gx8M9TXcsoGXCmF7+aQtpISfYFngNcObWVqJ0OuRa4E1hWVb4nU+sfgb8CHpzqQkbJgDO9ZEibfwlJ4yR5DPBvwOur6sdTXc9MV1UPVNUBdJ82f3CS/ae6ppkqyUuAO6vq6qmuZdQMONPLRn01hTSTJdmRLtz8a1V9aqrr0a9U1d3AZXjd2lQ6FHhZklvoLnM4PMlHprak0TDgTC9+NYU0iSQBzgZWVNW7p7oeQZLZSXZr0zsDLwK+M7VVzVxV9aaqmltV+9L9Drmkqv5oissaCQPONFJV64Gxr6ZYAVzgV1NMrSQfAy4Hnp5kdZKTp7qmGe5Q4I/p/iq9tj2OmeqiZri9gUuTXEf3R9qyqurtrcnafvhJxpIkqXc8giNJknrHgCNJknrHgCNJknrHgCNJknrHgCNJknrHgCNpQkne0r4B+rp2y/UhmznOAYO3ayd5WZJTt16lQ7d5WJLnTbDslUkeTPJbA23fal/vsDW2/ZMN95I0SgYcSUMleS7wEuDAqvotug9oWzX5WhM6AHgo4FTV0qp655ZXOanDgKEBp1kNvGXENWyyJLOmugapDww4kiayN/CjqrofoKp+VFW3ASQ5KMkXk1yd5KIke7f2y5K8K8nXk3w3yQvap26fDry8HQV6eTuC8k9tnXOSfDDJpUluTvLCJEuSrEhyzlgxSY5McnmSa5J8on3fFEluSfK21n59kme0IzGvAd7QtvmCIfv3OeBZSZ4+fsHgEZgkx4/VsbG1tr7/0Gq6OMns1vabSf69vW5fTvKMgXHfneRS4F2b/E5JehgDjqSJfAHYpwWVDyR5ITz0XU/vA46vqoOAJcAZA+vNqqqDgdcDp1XVL4C/BT5eVQdU1ceHbGt34HDgDcBngfcAzwL+Uzu9tSfwN8CLqupAYDnwXwfW/1Fr/yDwF1V1C/Ah4D1tm18ess0Hgb8D3ryJr8uktbY+uwDXtJq+CJzW2s8C/qy9bn8BfGBg3Ke1/XvjJtYjaQgPhUoaqqp+kuQg4AXA7wAfb9fNLAf2B5Z1X/3EDsDtA6uOfcHl1cC+G7m5z1ZVJbkeuKOqrgdIckMbYy6wH/DVts2d6L4iY9g2f3/j95KPAm9J8uRNWGdDtV5LF57GgtxHgE+1I07PAz7R9gHgkQPjfqKqHtiEOiRNwoAjaULtF+5lwGXtF/oiuhBxQ1U9d4LV7m/PD7Dx/8eMrfPgwPTY/Kw21rKqesVW3CZVtT7JPwB/PX7RwPSjNrHWoZuiO2J+d1UdMEGfn264Ykkby1NUkoZK8vQk8waaDgB+ANwIzG4XIZNkxyTP2sBw9wKP3YJyrgAOTfLUts1HJ3naVtrmOXQXUM8eaLsjyTOTPAL4vc2o9xHA8W36D4CvVNWPge8nOQG6bz5P8uzNGFvSRjDgSJrIY4Bzk3y7fRP0fsBb2zU1xwPvSvJNulMyk92tBHApsN/YRcabWkhVrQFeCXys1XIF8IwNrPZZ4Pcmuch4bOxfAGcCjx9oPpXuIuRL+PXTbxvrp3QXMF9Nd73O6a39D4GT2+t2A3DsZowtaSP4beKSJKl3PIIjSZJ6x4AjSZJ6x4AjSZJ6x4AjSZJ6x4AjSZJ6x4AjSZJ6x4AjSZJ6x4AjSZJ65/8HQxk9HM0Ji+YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets look at the distribution of the sentiment over the train data\n",
    "plt.figure(figsize = [9,6])\n",
    "sns.countplot(x=\"Sentiment\", data=train)\n",
    "plt.title('Sentiment distribution of movie reviews')\n",
    "plt.ylabel('Total')\n",
    "plt.xlabel('Sentiment Number')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Split train/test data for hold-out test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93636,) (93636,) (62424,) (62424,)\n",
      "almost in a class with that of Wilde\n",
      "3\n",
      "escape movie\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# check the sklearn documentation for train_test_split\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# \"test_size\" : float, int, None, optional\n",
    "# If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. \n",
    "# If int, represents the absolute number of test samples. \n",
    "# If None, the value is set to the complement of the train size. \n",
    "# By default, the value is set to 0.25. The default will change in version 0.21. It will remain 0.25 only if train_size is unspecified, otherwise it will complement the specified train_size.    \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.1 Data Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     1     2     3     4]\n",
      " [ 4141 16449 47718 19859  5469]]\n"
     ]
    }
   ],
   "source": [
    "# Checking whether the data set is balanced or skewed\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(np.asarray((unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     1     2     3     4]\n",
      " [ 2931 10824 31864 13068  3737]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(np.asarray((unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refernce- http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "#refernce- http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#  unigram boolean vectorizer\n",
    "unigram_bool_vectorizer = CountVectorizer(encoding='latin-1', binary=True,min_df =5, stop_words='english')\n",
    "\n",
    "#  unigram term frequency vectorizer\n",
    "unigram_count_vectorizer = CountVectorizer(encoding='latin-1', binary=False,min_df =5, stop_words='english')\n",
    "\n",
    "#  unigram and bigram term frequency vectorizer\n",
    "gram12_count_vectorizer = CountVectorizer(encoding='latin-1', ngram_range=(1,2),min_df =5,stop_words='english')\n",
    "\n",
    "#  unigram tfidf vectorizer\n",
    "unigram_tfidf_vectorizer = TfidfVectorizer(encoding='latin-1', use_idf=True,  min_df =5,stop_words='english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Vectorize the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93636, 11967)\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "11967\n",
      "[('class', 1858), ('wilde', 11742), ('derring', 2802), ('chilling', 1764), ('affecting', 313), ('meanspirited', 6557), ('personal', 7662), ('low', 6296), ('involved', 5602), ('worth', 11868)]\n"
     ]
    }
   ],
   "source": [
    "# fitting vocabulary in training documents and transforming the training documents into vectors\n",
    "X_train_vec = unigram_count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# checking the content of a document vector\n",
    "print(X_train_vec.shape)\n",
    "print(X_train_vec[0].toarray())\n",
    "\n",
    "# checking the size of the constructed vocabulary\n",
    "print(len(unigram_count_vectorizer.vocabulary_))\n",
    "\n",
    "# printing out the first 10 items in the vocabulary\n",
    "print(list(unigram_count_vectorizer.vocabulary_.items())[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Vectorize the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62424, 11967)\n"
     ]
    }
   ],
   "source": [
    "X_test_vec = unigram_count_vectorizer.transform(X_test)\n",
    "print(X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93636, 11967)\n",
      "(62424, 11967)\n"
     ]
    }
   ],
   "source": [
    "#refernce- http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\n",
    "X_train_vec = unigram_bool_vectorizer.fit_transform(X_train)\n",
    "print(X_train_vec.shape)\n",
    "X_test_vec = unigram_bool_vectorizer.transform(X_test)\n",
    "print(X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train a MNB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "(5, 11967)\n"
     ]
    }
   ],
   "source": [
    "# import the MNB module\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# initialize the MNB model\n",
    "nb_clf= MultinomialNB()\n",
    "\n",
    "# use the training data to train the MNB model\n",
    "nb_clf.fit(X_train_vec,y_train)\n",
    "print(nb_clf.classes_)\n",
    "print(nb_clf.feature_log_prob_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-5.946405317563997, 'time'), (-5.935710028447249, 'minutes'), (-5.925127919116712, 'characters'), (-5.925127919116712, 'story'), (-5.90429383221387, 'comedy'), (-5.6998813176057235, 'just'), (-5.195801081979265, 'like'), (-5.071833039257134, 'bad'), (-4.847793028895888, 'film'), (-4.322025825131698, 'movie')]\n"
     ]
    }
   ],
   "source": [
    "# sort the conditional probability for category 0 \"very negative\"\n",
    "# printing the words with highest conditional probs\n",
    "# these can be words popular in the \"very negative\" category alone, \n",
    "# or words popular in all cateogires\n",
    "\n",
    "feature_ranks = sorted(zip(nb_clf.feature_log_prob_[0], unigram_count_vectorizer.get_feature_names()))\n",
    "very_negative_features = feature_ranks[-10:]\n",
    "print(very_negative_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Testing the MNB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.606401384083045"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the classifier on the test data set\n",
    "#printing accuracy score\n",
    "nb_clf.score(X_test_vec,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  733  1264   817   106    11]\n",
      " [  602  4132  5411   649    30]\n",
      " [  246  2397 25756  3226   239]\n",
      " [   19   454  5580  6248   767]\n",
      " [    1    54   725  1972   985]]\n"
     ]
    }
   ],
   "source": [
    "# printing confusion matrix (row: ground truth; col: prediction)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = nb_clf.fit(X_train_vec, y_train).predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_pred, labels=[0,1,2,3,4])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45783885 0.49777135 0.67267361 0.51208917 0.48474409]\n",
      "[0.2500853  0.38174427 0.80831032 0.47811448 0.26358041]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.25      0.32      2931\n",
      "           1       0.50      0.38      0.43     10824\n",
      "           2       0.67      0.81      0.73     31864\n",
      "           3       0.51      0.48      0.49     13068\n",
      "           4       0.48      0.26      0.34      3737\n",
      "\n",
      "    accuracy                           0.61     62424\n",
      "   macro avg       0.53      0.44      0.47     62424\n",
      "weighted avg       0.59      0.61      0.59     62424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(precision_score(y_test, y_pred, average=None))\n",
    "print(recall_score(y_test, y_pred, average=None))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1','2','3','4']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "X_train_vec_bool = unigram_bool_vectorizer.fit_transform(X_train)\n",
    "bernoulliNB_clf = BernoulliNB(X_train_vec_bool, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5595474569680894\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "nb_clf_pipe = Pipeline([('vect', CountVectorizer(encoding='latin-1', binary=False)),('nb', MultinomialNB())])\n",
    "scores = cross_val_score(nb_clf_pipe, X, y, cv=3)\n",
    "avg=sum(scores)/len(scores)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cross validation with differnt vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5531524365695574\n",
      "0.5538446113746779\n",
      "0.5523067630016177\n",
      "0.5601369637205256\n"
     ]
    }
   ],
   "source": [
    "# run 3-fold cross validation to compare the performance of \n",
    "# (1) BernoulliNB (2) MultinomialNB with TF vectors (3) MultinomialNB with boolean vectors\n",
    "\n",
    "##Bernoulli\n",
    "bNB_pipe = Pipeline([('vect', CountVectorizer(encoding='latin-1',binary=False)),('bernNB',BernoulliNB())])\n",
    "scores = cross_val_score(bNB_pipe,X,y,cv=3)\n",
    "print(sum(scores)/len(scores))\n",
    "\n",
    "##MNB TFIDF\n",
    "mNB_tfidf_pipe = Pipeline([('nb_tf',TfidfVectorizer(encoding='latin-1',use_idf=True,binary=False)),('nb',MultinomialNB())])\n",
    "scores = cross_val_score(mNB_tfidf_pipe,X,y,cv=3)\n",
    "print(sum(scores)/len(scores))\n",
    "\n",
    "##MNB TF\n",
    "mNB_tf_pipe = Pipeline([('nb_tf',TfidfVectorizer(encoding='latin-1',use_idf=False,binary=False)),('nb',MultinomialNB())])\n",
    "scores = cross_val_score(mNB_tf_pipe,X,y,cv=3)\n",
    "print(sum(scores)/len(scores))\n",
    "\n",
    "##MNB with Bool\n",
    "nb_clf_pipe = Pipeline([('vect', CountVectorizer(encoding='latin-1', binary=True)),('nb', MultinomialNB())])\n",
    "scores = cross_val_score(nb_clf_pipe, X, y, cv=3)\n",
    "avg=sum(scores)/len(scores)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using external linguistic resources:- stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk.stem\n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([english_stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "stem_vectorizer = StemmedCountVectorizer(min_df=3, analyzer=\"word\")\n",
    "X_train_stem_vec = stem_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93636, 9968)\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "9968\n",
      "[('almost', 367), ('in', 4378), ('class', 1651), ('with', 9804), ('that', 8772), ('of', 6064), ('wild', 9763), ('whose', 9749), ('der', 2331), ('do', 2541)]\n"
     ]
    }
   ],
   "source": [
    "# checking the content of a document vector\n",
    "print(X_train_stem_vec.shape)\n",
    "print(X_train_stem_vec[0].toarray())\n",
    "\n",
    "# checking the size of the constructed vocabulary\n",
    "print(len(stem_vectorizer.vocabulary_))\n",
    "\n",
    "# printing out the first 10 items in the vocabulary\n",
    "print(list(stem_vectorizer.vocabulary_.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LinearSVC classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the LinearSVC module\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# initializing the LinearSVC model\n",
    "svm_clf = LinearSVC(C=1)\n",
    "\n",
    "# using the training data to train the model\n",
    "svm_clf.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  913  1229   696    79    14]\n",
      " [  705  4094  5472   527    26]\n",
      " [  190  2111 27063  2324   176]\n",
      " [   33   394  6011  5568  1062]\n",
      " [    3    51   582  1775  1326]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = svm_clf.fit(X_train_vec, y_train).predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_pred, labels=[0,1,2,3,4])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49511931 0.51960909 0.67956509 0.54200331 0.50921659]\n",
      "[0.31149778 0.37823356 0.8493284  0.42607897 0.35483008]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.31      0.38      2931\n",
      "           1       0.52      0.38      0.44     10824\n",
      "           2       0.68      0.85      0.76     31864\n",
      "           3       0.54      0.43      0.48     13068\n",
      "           4       0.51      0.35      0.42      3737\n",
      "\n",
      "    accuracy                           0.62     62424\n",
      "   macro avg       0.55      0.46      0.49     62424\n",
      "weighted avg       0.60      0.62      0.60     62424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing classification report\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(precision_score(y_test, y_pred, average=None))\n",
    "print(recall_score(y_test, y_pred, average=None))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1','2','3','4']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very negative words\n",
      "(1.6275629476015396, 'cesspool')\n",
      "(1.6637718518540685, 'pompous')\n",
      "(1.6918278618171216, 'stinks')\n",
      "(1.6987737759479684, 'distasteful')\n",
      "(1.712167609810901, 'unwatchable')\n",
      "(1.7288295066294603, 'disappointment')\n",
      "(1.759290357596579, 'unbearable')\n",
      "(1.8085408043365854, 'stinker')\n",
      "(1.8268012356632481, 'worthless')\n",
      "(1.8341330416307624, 'disgusting')\n",
      "\n",
      "not very negative words\n",
      "(-1.8437632060702926, 'hawke')\n",
      "(-1.6993728108553068, 'collar')\n",
      "(-1.6976858613154775, 'giddy')\n",
      "(-1.5910864212565061, 'swimfan')\n",
      "(-1.5714608003054282, 'blue')\n",
      "(-1.4870190325221853, 'dogtown')\n",
      "(-1.4322894732858364, 'victim')\n",
      "(-1.41585093536706, 'joan')\n",
      "(-1.4137338227176226, 'won')\n",
      "(-1.4045009839086844, 'innocence')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## digging deeper and printing out some negative words to see what scores are assigned\n",
    "## For category \"0\" (very negative), geting all features and their weights and sorting them in increasing order\n",
    "feature_ranks = sorted(zip(svm_clf.coef_[0], unigram_count_vectorizer.get_feature_names()))\n",
    "\n",
    "## printing features that are best indicators of very negative sentiment\n",
    "very_negative_10 = feature_ranks[-10:]\n",
    "print(\"Very negative words\")\n",
    "for i in range(0, len(very_negative_10)):\n",
    "    print(very_negative_10[i])\n",
    "print()\n",
    "\n",
    "## printing 10 features that are least relevant to \"very negative\" sentiment\n",
    "not_very_negative_10 = feature_ranks[:10]\n",
    "print(\"not very negative words\")\n",
    "for i in range(0, len(not_very_negative_10)):\n",
    "    print(not_very_negative_10[i])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66287</td>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66288</td>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66289</td>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66290</td>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66291</td>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId                                             Phrase\n",
       "0        156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1        156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2        156063        8545                                                 An\n",
       "3        156064        8545  intermittently pleasing but mostly routine effort\n",
       "4        156065        8545         intermittently pleasing but mostly routine\n",
       "...         ...         ...                                                ...\n",
       "66287    222348       11855             A long-winded , predictable scenario .\n",
       "66288    222349       11855               A long-winded , predictable scenario\n",
       "66289    222350       11855                                    A long-winded ,\n",
       "66290    222351       11855                                      A long-winded\n",
       "66291    222352       11855                               predictable scenario\n",
       "\n",
       "[66292 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the output file of the best performing model\n",
    "y_pred=svm_clf.predict(X_test_vec)\n",
    "output = open('C:\\\\Users\\\\Divya\\\\Desktop\\\\Syracuse University\\\\summer Sem\\\\NLP Project\\\\FinalProjectData\\\\FinalProjectData\\\\kagglemoviereviews\\\\linearSVC_prediction_output.csv', 'w')\n",
    "for x, value in enumerate(y_pred):\n",
    "    output.write(str(value) + '\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66292 entries, 0 to 66291\n",
      "Data columns (total 3 columns):\n",
      "PhraseId      66292 non-null int64\n",
      "SentenceId    66292 non-null int64\n",
      "Phrase        66292 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = open('C:\\\\Users\\\\Divya\\\\Desktop\\\\Syracuse University\\\\summer Sem\\\\NLP Project\\\\FinalProjectData\\\\FinalProjectData\\\\kagglemoviereviews\\\\linearSVC_prediction_output2.csv', 'w')\n",
    "for x, value in enumerate(test['PhraseId']):\n",
    "    output.write(str(test['PhraseId']) + '\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('C:\\\\Users\\\\Divya\\\\Desktop\\\\Syracuse University\\\\summer Sem\\\\NLP Project\\\\FinalProjectData\\\\FinalProjectData\\\\kagglemoviereviews\\\\linearSVC_prediction_output3.csv', 'w')\n",
    "#for id in test['PhraseId']:\n",
    " #   x = str(test['PhraseId'])\n",
    "  #  output.write(x)\n",
    "#output.close  ##\n",
    "for x, value in enumerate(test['PhraseId']):\n",
    "    output.write(str(value) + '\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6241830065359477"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.score(X_test_vec,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Divya\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Divya\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Divya\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Divya\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5365306212276564\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "clf_pipe = Pipeline([('vect', CountVectorizer(encoding='latin-1', binary=False)),('rf', RandomForestClassifier())])\n",
    "scores = cross_val_score(clf_pipe, X, y, cv=3)\n",
    "avg=sum(scores)/len(scores)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion is given in detail in the report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
